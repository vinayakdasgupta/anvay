@inproceedings{rehurek_lrec,
      title = {{Software framework for topic modelling with large corpora}},
      author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
      booktitle = "Proceedings of the {LREC} 2010 workshop on {New Challenges for NLP Frameworks}",
      pages = {45--50},
      year = 2010,
      month = may,
      day = 22,
      publisher = {ELRA},
      address = {Valletta, Malta},
      note={\url{http://is.muni.cz/publication/884893/en}},
      language={English}
}

@inproceedings{chakrabarty-etal-2017-context,
    title = "Context sensitive lemmatization using two successive bidirectional gated recurrent networks",
    author = "Chakrabarty, Abhisek  and
      Pandit, Onkar Arun  and
      Garain, Utpal",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th annual meeting of the {Association for Computational Linguistics} (volume 1: long papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1136/",
    doi = "10.18653/v1/P17-1136",
    pages = "1481--1491"
}

@article{alam2021review,
  title={A review of {B}angla natural language processing tasks and the utility of transformer models},
  author={Alam, Firoj and Hasan, Md. Ashraful and Alam, Tanvir and Khan, Akib and Tajrin, Jannatul and Khan, Nayeem and Chowdhury, Shammur Absar},
  journal={arXiv preprint arXiv:2107.03844},
  year={2021},
  archivePrefix={arXiv},
  eprint={2107.03844}
}

@misc{voyant,
  title={Voyant Tools},
  author={Sinclair, Stéfan and Rockwell, Geoffrey},
  year={2016},
  howpublished={https://voyant-tools.org/}
}

@inproceedings{bianchi-etal-2021-pre,
    title = "Pre-training is a hot topic: Contextualized document embeddings improve topic coherence",
    author = "Bianchi, Federico  and
      Terragni, Silvia  and
      Hovy, Dirk",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th annual meeting of the {Association for Computational Linguistics} and the {11th International Joint Conference on Natural Language Processing} (volume 2: short papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-short.96/",
    doi = "10.18653/v1/2021.acl-short.96",
    pages = "759--766",
    abstract = "Topic models extract groups of words from documents, whose interpretation as a topic hopefully allows for a better understanding of the data. However, the resulting word groups are often not coherent, making them harder to interpret. Recently, neural topic models have shown improvements in overall coherence. Concurrently, contextual embeddings have advanced the state of the art of neural models in general. In this paper, we combine contextualized representations with neural topic models. We find that our approach produces more meaningful and coherent topics than traditional bag-of-words topic models and recent neural models. Our results indicate that future improvements in language models will translate into better topic models."
}


@article{goldstone2014quiet,
  title={The quiet transformations of literary studies: What thirteen thousand scholars could tell us},
  author={Goldstone, Andrew and Underwood, Ted},
  journal={New Literary History},
  volume={45},
  number={3},
  pages={359--384},
  year={2014},
  doi={10.1353/nlh.2014.0025}
}

@inproceedings{chuang2012termite,
author = {Chuang, Jason and Manning, Christopher D. and Heer, Jeffrey},
title = {{T}ermite: Visualization techniques for assessing textual topic models},
year = {2012},
isbn = {9781450312875},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254556.2254572},
doi = {10.1145/2254556.2254572},
abstract = {Topic models aid analysis of text corpora by identifying latent topics based on co-occurring words. Real-world deployments of topic models, however, often require intensive expert verification and model refinement. In this paper we present Termite, a visual analysis tool for assessing topic model quality. Termite uses a tabular layout to promote comparison of terms both within and across latent topics. We contribute a novel saliency measure for selecting relevant terms and a seriation algorithm that both reveals clustering structure and promotes the legibility of related terms. In a series of examples, we demonstrate how Termite allows analysts to identify coherent and significant themes.},
booktitle = "Proceedings of the {International Working Conference on Advanced Visual Interfaces}",
pages = {74–77},
numpages = {4},
keywords = {topic models, text visualization, seriation},
location = {Capri Island, Italy},
series = {AVI '12}
}

@article{blei2003lda,
author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
title = {Latent Dirichlet allocation},
year = {2003},
issue_date = {3/1/2003},
publisher = {JMLR.org},
volume = {3},
issn = {1532-4435},
abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
journal = {Journal of Machine Learning Research},
month = mar,
pages = {993--1022},
numpages = {30}
}

@inproceedings{sievert-shirley-2014-ldavis,
    title = {{LDAvis}: A method for visualizing and interpreting topics},
    author = "Sievert, Carson  and
      Shirley, Kenneth",
    editor = "Chuang, Jason  and
      Green, Spence  and
      Hearst, Marti  and
      Heer, Jeffrey  and
      Koehn, Philipp",
    booktitle = "Proceedings of the {Workshop on Interactive Language Learning, Visualization, and Interfaces}",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W14-3110/",
    doi = "10.3115/v1/W14-3110",
    pages = "63--70"
}

@misc{kardos2025topicwizardmodernmodelagnostic,
      title={{topicwizard} -- A modern, model-agnostic framework for topic model visualization and interpretation}, 
      author={Márton Kardos and Kenneth C. Enevoldsen and Kristoffer Laigaard Nielbo},
      year={2025},
      eprint={2505.13034},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.13034}, 
}

@misc{mimno_jslda,
  title={js{LDA}: In-browser topic modeling},
  author={Mimno, David},
  howpublished={\url{https://github.com/mimno/jsLDA}},
  note={Accessed 2025}
}

@misc{enderle2019topictool,
  title={Topic modeling tool},
  author={Enderle, Scott},
  year={2019},
  howpublished={\url{https://github.com/senderle/topic-modeling-tool}},
  note={Accessed 2025}
}

@misc{goldstone2014dfrbrowser,
  title={{DFR}-Browser},
  author={Goldstone, Andrew and Underwood, Ted},
  year={2014},
  howpublished={\url{https://github.com/agoldst/dfr-browser}},
  note={Accessed 2025}
}

@misc{grootendorst2022bertopic,
      title={{BERT}opic: Neural topic modeling with a class-based {TF-IDF} procedure}, 
      author={Maarten Grootendorst},
      year={2022},
      eprint={2203.05794},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.05794}, 
}


@misc{angelov2020top2vec,
      title={{Top2Vec}: Distributed representations of topics}, 
      author={Dimo Angelov},
      year={2020},
      eprint={2008.09470},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2008.09470}, 
}

@misc{mccallum2002mallet,
  title        = {{MALLET}: A machine learning for language toolkit},
  author       = {McCallum, Andrew K.},
  howpublished = {\url{http://mallet.cs.umass.edu/}},
  year         = {2002},
  note         = {Accessed 2025}
}

@article{Waskom2021,
    doi = {10.21105/joss.03021},
    url = {https://doi.org/10.21105/joss.03021},
    year = {2021},
    publisher = {The Open Journal},
    volume = {6},
    number = {60},
    pages = {3021},
    author = {Michael L. Waskom},
    title = {{seaborn}: Statistical data visualization},
    journal = {Journal of Open Source Software}
 }

@inproceedings{hagberg2008exploring,
  author = {Hagberg, Aric A. and Schult, Daniel A. and Swart, Pieter J.},
  doi = {10.25080/tcwv9851},
  title = {Exploring network structure, dynamics, and function using {NetworkX}},
  booktitle = "Proceedings of the {7th Python in Science Conference (SciPy2008)}",
  pages = {11--15},
  year = {2008}
}

@book{bird2009natural,
  author = {Bird, Steven and Klein, Ewan and Loper, Edward},
  title = {Natural language processing with {P}ython},
  year = {2009},
  publisher = {O'Reilly Media, Inc.}
}

@book{jockers2013macroanalysis,
  title={Macroanalysis: Digital methods and literary history},
  author={Jockers, Matthew L.},
  year={2013},
  publisher={University of Illinois Press}
}